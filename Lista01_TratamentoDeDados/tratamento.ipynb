{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d05e41e",
   "metadata": {},
   "source": [
    "# CK0223 - Mineração de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd9a9e",
   "metadata": {},
   "source": [
    "## Lista 01 - Tratamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb4e2e",
   "metadata": {},
   "source": [
    "### Dados do discente:\n",
    "**Nome**: Luiza Esther Martins Pessoa\n",
    "**Matrícula**: 555516\n",
    "\n",
    "### Vídeo Youtube:\n",
    "[Mineração de Dados: Lista 01 - Tratamento de Dados (Explicando o código)]( https://youtu.be/39lvoBmO9us)\n",
    "\n",
    "---\n",
    "\n",
    "### Informações inicias:\n",
    "Esta tarefa busca exercitar os conceitos refrentes à manipulação, tratamento e limpeza de dados. Com isso, além de criar scripts que resolvam às solicitações de cada item da atividade, este notebook armazenará comentários adicionais referentes ao processo de desenvolvimento de ideias e fontes que foram consultadas.\n",
    "\n",
    "Como estamos seguindo um processo de tratamento de dados estruturado, não irei adicionar mais um script de importação de bibliotecas, apenas em casos em que será necessário importar uma biblioteca diferente das que já utilizamos em itens anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63397d",
   "metadata": {},
   "source": [
    "### **(a)** Ler o dataset *fakeTelegram.BR_2022.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1f40a",
   "metadata": {},
   "source": [
    "Como estamos trabalhando com uma grande quantidade de dados, utilizar uma lista não é tão visualmente intuitivo e um dataframe consegue ser mais fácil de manipular dados, pois é como se estivessemos visualizando uma planilha.\n",
    "\n",
    "Além disso, vamos utilizar a biblioteca *pandas* para ler o arquivo `.csv` utilizando a chamada `read_csv`. Porém, antes de fazer isso, é importante analisar a origem da nossa base de dados, ou seja, onde essa base está armazenada. No caso da *fakeTelegram.BR_2022.csv* podemos fazer de duas formas, visto que sua origem vem do Google Drive:\n",
    "\n",
    "1. Usando apenas a biblioteca *pandas* -- Se o arquivo for público ou compartilhado com o link, você pode gerar uma URL direta de download. \n",
    "2. Usando a biblioteca *request* para transformar o link de compartilhamento em um link de download e depois utilizar *pandas* para ler o dataframe gerado. -- Basicamente, usamos o requests para baixar o conteúdo do arquivo primeiro como um binário (.content), e depois passa o conteúdo como um buffer para o pandas ler.\n",
    "\n",
    "Contudo, antes de fazer isso, como o arquivo é muito grande, foi necessário extrair o arquivo para a máquina local e para fazer isso, utiizei a biblioteca `gdown` que simula o comportamento de um navegador e lida automaticamente com o redirecionamento e o botão de \"Download mesmo assim\" que aparece para arquivos grandes no Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8948ccd",
   "metadata": {},
   "source": [
    "#### **Passo 01**\n",
    "Importando bibliotecas necessárias para leitura do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc6a2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÃO DE BIBLIOTECAS\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f32199",
   "metadata": {},
   "source": [
    "#### **Passo 02**\n",
    "Fazendo o download da base de dados para local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "origem_url = 'https://drive.google.com/file/d/1c_hLzk85pYw-huHSnFYZM_gn-dUsYRDm/view'\n",
    "\n",
    "# O ID do arquivo (necessário para fazer o download direto) está entre os últimos elementos da URL.\n",
    "# Fazemos um split na URL usando '/' como separador e pegamos o penúltimo elemento da lista.\n",
    "# Isso funciona porque a estrutura da URL é:\n",
    "# https://drive.google.com/file/d/ID_DO_ARQUIVO/view\n",
    "# E ao aplicar url.split('/'), o resultado será:\n",
    "# ['https:', '', 'drive.google.com', 'file', 'd', 'ID_DO_ARQUIVO', 'view?...']\n",
    "# Portanto, o ID está na posição -2 (penúltima).\n",
    "\n",
    "file_id = origem_url.split('/')[-2]\n",
    "\n",
    "# URL do arquivo no formato aceito pelo gdown\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Nome local do arquivo que será baixado\n",
    "output = 'fakeTelegram.BR_2022.csv'\n",
    "\n",
    "# Baixando o arquivo com gdown\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae655b2",
   "metadata": {},
   "source": [
    "#### **Passo 03**\n",
    "Lendo utilizando apenas pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1f45cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inicial = pd.read_csv(\"fakeTelegram.BR_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bea1e",
   "metadata": {},
   "source": [
    "#### **Passo 04**\n",
    "Conferindo informações iniciais após leitura da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a0580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas: 557586\n",
      "Número de colunas: 19\n",
      "Nome das colunas: Index(['date_message', 'id_member_anonymous', 'id_group_anonymous', 'media',\n",
      "       'media_type', 'media_url', 'has_media', 'has_media_url', 'trava_zap',\n",
      "       'text_content_anonymous', 'dataset_info_id', 'date_system',\n",
      "       'score_sentiment', 'score_misinformation', 'id_message', 'message_type',\n",
      "       'messenger', 'media_name', 'media_md5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# PARA MELHOR VISUALIZAÇÃO\n",
    "print(\"Número de linhas:\", df_inicial.shape[0])\n",
    "print(\"Número de colunas:\", df_inicial.shape[1])\n",
    "print(\"Nome das colunas:\", df_inicial.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d5b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 5 linhas do dataset:\n",
      "          date_message               id_member_anonymous  \\\n",
      "0  2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
      "1  2022-10-05 06:25:08                               NaN   \n",
      "2  2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
      "3  2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
      "4  2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
      "\n",
      "                 id_group_anonymous                                 media  \\\n",
      "0  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
      "1  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
      "2  9f2d7394334eb224c061c9740b5748fc                                   NaN   \n",
      "3  c8f2de56550ed0bf85249608b7ead93d  94dca4cda503100ebfda7ce2bcc060eb.jpg   \n",
      "4  e56ec342fc599ebb4ed89655eb6f03aa  5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg   \n",
      "\n",
      "  media_type media_url  has_media  has_media_url  trava_zap  \\\n",
      "0        NaN       NaN      False          False      False   \n",
      "1        NaN       NaN      False          False      False   \n",
      "2        NaN       NaN      False          False      False   \n",
      "3  image/jpg       NaN       True          False      False   \n",
      "4  image/jpg       NaN       True          False      False   \n",
      "\n",
      "                              text_content_anonymous  dataset_info_id  \\\n",
      "0  Então é Fato Renato o áudio que eu ouvi no wha...                5   \n",
      "1  Saiu no YouTube do presidente a 8 horas atrás,...                5   \n",
      "2  É isso, nossa parte já foi quase toda feita. N...                5   \n",
      "3           GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA                5   \n",
      "4                                                NaN                5   \n",
      "\n",
      "                  date_system  score_sentiment  score_misinformation  \\\n",
      "0  2022-10-05 06:25:28.863641           0.0000                   NaN   \n",
      "1  2022-10-05 06:25:28.926311           0.0644                   NaN   \n",
      "2  2022-10-05 06:26:29.361949          -0.3551              0.157242   \n",
      "3  2022-10-05 06:27:29.935624           0.0000                   NaN   \n",
      "4  2022-10-05 06:28:29.316325              NaN                   NaN   \n",
      "\n",
      "   id_message message_type messenger media_name  \\\n",
      "0       16385        Texto  telegram        NaN   \n",
      "1       16386        Texto  telegram        NaN   \n",
      "2       16366        Texto  telegram        NaN   \n",
      "3       19281       Imagem  telegram        NaN   \n",
      "4      507185       Imagem  telegram        NaN   \n",
      "\n",
      "                          media_md5  \n",
      "0                               NaN  \n",
      "1                               NaN  \n",
      "2                               NaN  \n",
      "3  94dca4cda503100ebfda7ce2bcc060eb  \n",
      "4  5ad5c8bbe9da93a37fecf3e5aa5b0637  \n",
      "Últimas 5 linhas do dataset:\n",
      "               date_message               id_member_anonymous  \\\n",
      "557581  2022-11-11 12:06:15  333e9869f23dbd4682d1be382d9c1e59   \n",
      "557582  2022-11-11 12:09:08                               NaN   \n",
      "557583  2022-11-11 12:09:47                               NaN   \n",
      "557584  2022-11-11 12:09:46                               NaN   \n",
      "557585  2022-11-11 12:09:48                               NaN   \n",
      "\n",
      "                      id_group_anonymous  \\\n",
      "557581  e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "557582  5b10d7739171149be6d9961e3350c071   \n",
      "557583  1590a03f43b5ba4b6147a1c5e1dd357b   \n",
      "557584  5b10d7739171149be6d9961e3350c071   \n",
      "557585  b11f2df64ac19aad47a50accf32052d6   \n",
      "\n",
      "                                       media media_type  \\\n",
      "557581  25e43b6a58b848c43ad5b5f9e979822a.jpg        url   \n",
      "557582  657949d03e4088f6b332e2686ccd3221.jpg        url   \n",
      "557583  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557584  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557585  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "\n",
      "                                                media_url  has_media  \\\n",
      "557581  https://terrabrasilnoticias.com/2022/11/bndes-...       True   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk       True   \n",
      "557583                           https://t.me/vemprasruas       True   \n",
      "557584                           https://t.me/vemprasruas       True   \n",
      "557585                           https://t.me/vemprasruas       True   \n",
      "\n",
      "        has_media_url  trava_zap  \\\n",
      "557581           True      False   \n",
      "557582           True      False   \n",
      "557583           True      False   \n",
      "557584           True      False   \n",
      "557585           True      False   \n",
      "\n",
      "                                   text_content_anonymous  dataset_info_id  \\\n",
      "557581  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...                5   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk                5   \n",
      "557583  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "557584  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "557585  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "\n",
      "                       date_system  score_sentiment  score_misinformation  \\\n",
      "557581  2022-11-16 14:49:39.146502           0.1027                   NaN   \n",
      "557582  2022-11-16 14:49:39.847434           0.0000                   NaN   \n",
      "557583  2022-11-16 14:49:39.922279           0.0000                   NaN   \n",
      "557584  2022-11-16 14:49:39.992932           0.0000                   NaN   \n",
      "557585  2022-11-16 14:49:40.064006           0.0000                   NaN   \n",
      "\n",
      "        id_message message_type messenger media_name  \\\n",
      "557581      575796          Url  telegram        NaN   \n",
      "557582     1286443          Url  telegram        NaN   \n",
      "557583       13294       Imagem  telegram        NaN   \n",
      "557584     1286444       Imagem  telegram        NaN   \n",
      "557585      192127       Imagem  telegram        NaN   \n",
      "\n",
      "                               media_md5  \n",
      "557581  25e43b6a58b848c43ad5b5f9e979822a  \n",
      "557582  657949d03e4088f6b332e2686ccd3221  \n",
      "557583  a21848a61045380a6483866daed0ca0e  \n",
      "557584  a21848a61045380a6483866daed0ca0e  \n",
      "557585  a21848a61045380a6483866daed0ca0e  \n"
     ]
    }
   ],
   "source": [
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "print(df_inicial.head())\n",
    "\n",
    "print(\"Últimas 5 linhas do dataset:\")\n",
    "print(df_inicial.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f22785",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a94ae",
   "metadata": {},
   "source": [
    "### **(b)** Identificar e listar as posições (células) contendo valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81011813",
   "metadata": {},
   "source": [
    "A biblioteca *pandas* será utilizada novamente neste item e, como já importamos no **item a**, não será necessário realizar um novo script de `import`.\n",
    "\n",
    "Como vimos em sala de aula, é imprescíndivel realizar a identificação e listagem das células que contém valores faltantes, pois esses dados podem impactar diretamente nossas estimativas futuras. Portanto, não estou removendo nenhuma célula da base de dados, apenas analisando os dados `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d591efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date_message               id_member_anonymous  \\\n",
      "0       2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
      "1       2022-10-05 06:25:08                               NaN   \n",
      "2       2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
      "3       2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
      "4       2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
      "...                     ...                               ...   \n",
      "557581  2022-11-11 12:06:15  333e9869f23dbd4682d1be382d9c1e59   \n",
      "557582  2022-11-11 12:09:08                               NaN   \n",
      "557583  2022-11-11 12:09:47                               NaN   \n",
      "557584  2022-11-11 12:09:46                               NaN   \n",
      "557585  2022-11-11 12:09:48                               NaN   \n",
      "\n",
      "                      id_group_anonymous  \\\n",
      "0       12283e08a2eb5789201e105b34489ee7   \n",
      "1       12283e08a2eb5789201e105b34489ee7   \n",
      "2       9f2d7394334eb224c061c9740b5748fc   \n",
      "3       c8f2de56550ed0bf85249608b7ead93d   \n",
      "4       e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "...                                  ...   \n",
      "557581  e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "557582  5b10d7739171149be6d9961e3350c071   \n",
      "557583  1590a03f43b5ba4b6147a1c5e1dd357b   \n",
      "557584  5b10d7739171149be6d9961e3350c071   \n",
      "557585  b11f2df64ac19aad47a50accf32052d6   \n",
      "\n",
      "                                       media media_type  \\\n",
      "0                                        NaN        NaN   \n",
      "1                                        NaN        NaN   \n",
      "2                                        NaN        NaN   \n",
      "3       94dca4cda503100ebfda7ce2bcc060eb.jpg  image/jpg   \n",
      "4       5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg  image/jpg   \n",
      "...                                      ...        ...   \n",
      "557581  25e43b6a58b848c43ad5b5f9e979822a.jpg        url   \n",
      "557582  657949d03e4088f6b332e2686ccd3221.jpg        url   \n",
      "557583  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557584  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557585  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "\n",
      "                                                media_url  has_media  \\\n",
      "0                                                     NaN      False   \n",
      "1                                                     NaN      False   \n",
      "2                                                     NaN      False   \n",
      "3                                                     NaN       True   \n",
      "4                                                     NaN       True   \n",
      "...                                                   ...        ...   \n",
      "557581  https://terrabrasilnoticias.com/2022/11/bndes-...       True   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk       True   \n",
      "557583                           https://t.me/vemprasruas       True   \n",
      "557584                           https://t.me/vemprasruas       True   \n",
      "557585                           https://t.me/vemprasruas       True   \n",
      "\n",
      "        has_media_url  trava_zap  \\\n",
      "0               False      False   \n",
      "1               False      False   \n",
      "2               False      False   \n",
      "3               False      False   \n",
      "4               False      False   \n",
      "...               ...        ...   \n",
      "557581           True      False   \n",
      "557582           True      False   \n",
      "557583           True      False   \n",
      "557584           True      False   \n",
      "557585           True      False   \n",
      "\n",
      "                                   text_content_anonymous  dataset_info_id  \\\n",
      "0       Então é Fato Renato o áudio que eu ouvi no wha...                5   \n",
      "1       Saiu no YouTube do presidente a 8 horas atrás,...                5   \n",
      "2       É isso, nossa parte já foi quase toda feita. N...                5   \n",
      "3                GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA                5   \n",
      "4                                                     NaN                5   \n",
      "...                                                   ...              ...   \n",
      "557581  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...                5   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk                5   \n",
      "557583  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "557584  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "557585  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
      "\n",
      "                       date_system  score_sentiment  score_misinformation  \\\n",
      "0       2022-10-05 06:25:28.863641           0.0000                   NaN   \n",
      "1       2022-10-05 06:25:28.926311           0.0644                   NaN   \n",
      "2       2022-10-05 06:26:29.361949          -0.3551              0.157242   \n",
      "3       2022-10-05 06:27:29.935624           0.0000                   NaN   \n",
      "4       2022-10-05 06:28:29.316325              NaN                   NaN   \n",
      "...                            ...              ...                   ...   \n",
      "557581  2022-11-16 14:49:39.146502           0.1027                   NaN   \n",
      "557582  2022-11-16 14:49:39.847434           0.0000                   NaN   \n",
      "557583  2022-11-16 14:49:39.922279           0.0000                   NaN   \n",
      "557584  2022-11-16 14:49:39.992932           0.0000                   NaN   \n",
      "557585  2022-11-16 14:49:40.064006           0.0000                   NaN   \n",
      "\n",
      "        id_message message_type messenger media_name  \\\n",
      "0            16385        Texto  telegram        NaN   \n",
      "1            16386        Texto  telegram        NaN   \n",
      "2            16366        Texto  telegram        NaN   \n",
      "3            19281       Imagem  telegram        NaN   \n",
      "4           507185       Imagem  telegram        NaN   \n",
      "...            ...          ...       ...        ...   \n",
      "557581      575796          Url  telegram        NaN   \n",
      "557582     1286443          Url  telegram        NaN   \n",
      "557583       13294       Imagem  telegram        NaN   \n",
      "557584     1286444       Imagem  telegram        NaN   \n",
      "557585      192127       Imagem  telegram        NaN   \n",
      "\n",
      "                               media_md5  \n",
      "0                                    NaN  \n",
      "1                                    NaN  \n",
      "2                                    NaN  \n",
      "3       94dca4cda503100ebfda7ce2bcc060eb  \n",
      "4       5ad5c8bbe9da93a37fecf3e5aa5b0637  \n",
      "...                                  ...  \n",
      "557581  25e43b6a58b848c43ad5b5f9e979822a  \n",
      "557582  657949d03e4088f6b332e2686ccd3221  \n",
      "557583  a21848a61045380a6483866daed0ca0e  \n",
      "557584  a21848a61045380a6483866daed0ca0e  \n",
      "557585  a21848a61045380a6483866daed0ca0e  \n",
      "\n",
      "[557586 rows x 19 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_info_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score_sentiment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score_misinformation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "id_message",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "308c23fd-e336-4b6d-b5cd-cbe0a96065ac",
       "rows": [
        [
         "count",
         "557586.0",
         "444157.0",
         "167238.0",
         "557586.0"
        ],
        [
         "mean",
         "5.0",
         "0.017329966881080332",
         "0.3122449940127795",
         "445061.6788172587"
        ],
        [
         "std",
         "0.0",
         "0.4641649427047041",
         "0.29369857324799187",
         "486021.05909007107"
        ],
        [
         "min",
         "5.0",
         "-1.0",
         "3.2731487153e-06",
         "2.0"
        ],
        [
         "25%",
         "5.0",
         "-0.1779",
         "0.07845421598864155",
         "21275.0"
        ],
        [
         "50%",
         "5.0",
         "0.0",
         "0.1975767606336799",
         "121093.5"
        ],
        [
         "75%",
         "5.0",
         "0.3182",
         "0.4903506818386002",
         "972604.5"
        ],
        [
         "max",
         "5.0",
         "0.9992",
         "0.9999999828564162",
         "1516436.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_info_id</th>\n",
       "      <th>score_sentiment</th>\n",
       "      <th>score_misinformation</th>\n",
       "      <th>id_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>557586.0</td>\n",
       "      <td>444157.000000</td>\n",
       "      <td>167238.000000</td>\n",
       "      <td>5.575860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.312245</td>\n",
       "      <td>4.450617e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464165</td>\n",
       "      <td>0.293699</td>\n",
       "      <td>4.860211e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.177900</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>2.127500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197577</td>\n",
       "      <td>1.210935e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.318200</td>\n",
       "      <td>0.490351</td>\n",
       "      <td>9.726045e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.516436e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset_info_id  score_sentiment  score_misinformation    id_message\n",
       "count         557586.0    444157.000000         167238.000000  5.575860e+05\n",
       "mean               5.0         0.017330              0.312245  4.450617e+05\n",
       "std                0.0         0.464165              0.293699  4.860211e+05\n",
       "min                5.0        -1.000000              0.000003  2.000000e+00\n",
       "25%                5.0        -0.177900              0.078454  2.127500e+04\n",
       "50%                5.0         0.000000              0.197577  1.210935e+05\n",
       "75%                5.0         0.318200              0.490351  9.726045e+05\n",
       "max                5.0         0.999200              1.000000  1.516436e+06"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VISUALIZANDO NOVAMENTE O NOSSO DATAFRAME\n",
    "print(df_inicial)\n",
    "df_inicial.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d450cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date_message  id_member_anonymous  id_group_anonymous  media  \\\n",
      "0              False                False               False   True   \n",
      "1              False                 True               False   True   \n",
      "2              False                False               False   True   \n",
      "3              False                False               False  False   \n",
      "4              False                False               False  False   \n",
      "...              ...                  ...                 ...    ...   \n",
      "557581         False                False               False  False   \n",
      "557582         False                 True               False  False   \n",
      "557583         False                 True               False  False   \n",
      "557584         False                 True               False  False   \n",
      "557585         False                 True               False  False   \n",
      "\n",
      "        media_type  media_url  has_media  has_media_url  trava_zap  \\\n",
      "0             True       True      False          False      False   \n",
      "1             True       True      False          False      False   \n",
      "2             True       True      False          False      False   \n",
      "3            False       True      False          False      False   \n",
      "4            False       True      False          False      False   \n",
      "...            ...        ...        ...            ...        ...   \n",
      "557581       False      False      False          False      False   \n",
      "557582       False      False      False          False      False   \n",
      "557583       False      False      False          False      False   \n",
      "557584       False      False      False          False      False   \n",
      "557585       False      False      False          False      False   \n",
      "\n",
      "        text_content_anonymous  dataset_info_id  date_system  score_sentiment  \\\n",
      "0                        False            False        False            False   \n",
      "1                        False            False        False            False   \n",
      "2                        False            False        False            False   \n",
      "3                        False            False        False            False   \n",
      "4                         True            False        False             True   \n",
      "...                        ...              ...          ...              ...   \n",
      "557581                   False            False        False            False   \n",
      "557582                   False            False        False            False   \n",
      "557583                   False            False        False            False   \n",
      "557584                   False            False        False            False   \n",
      "557585                   False            False        False            False   \n",
      "\n",
      "        score_misinformation  id_message  message_type  messenger  media_name  \\\n",
      "0                       True       False         False      False        True   \n",
      "1                       True       False         False      False        True   \n",
      "2                      False       False         False      False        True   \n",
      "3                       True       False         False      False        True   \n",
      "4                       True       False         False      False        True   \n",
      "...                      ...         ...           ...        ...         ...   \n",
      "557581                  True       False         False      False        True   \n",
      "557582                  True       False         False      False        True   \n",
      "557583                  True       False         False      False        True   \n",
      "557584                  True       False         False      False        True   \n",
      "557585                  True       False         False      False        True   \n",
      "\n",
      "        media_md5  \n",
      "0            True  \n",
      "1            True  \n",
      "2            True  \n",
      "3           False  \n",
      "4           False  \n",
      "...           ...  \n",
      "557581      False  \n",
      "557582      False  \n",
      "557583      False  \n",
      "557584      False  \n",
      "557585      False  \n",
      "\n",
      "[557586 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_inicial.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c9e04",
   "metadata": {},
   "source": [
    "O script abaixo é considerado um pouco \"pesado\" visto que está iterando sobre as linhas da base de dados e realizando um print todas as vezes que encontrar um valor NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75c4d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 524k/224M [05:51<41:32:07, 1.49kB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# EXIBINDO OS RESULTADOS\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Identifica as posições (índices e colunas) onde há valores faltantes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m missing_positions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_inicial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Exibe as posições encontradas\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m missing_positions:\n",
      "File \u001b[1;32mc:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1453\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1451\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1453\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1455\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:636\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    633\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    634\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 636\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:689\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult should be arraylike with ndim > 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;66;03m# the result that we want\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_repeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:732\u001b[0m, in \u001b[0;36m_maybe_repeat\u001b[1;34m(arr, index)\u001b[0m\n\u001b[0;32m    728\u001b[0m             result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_repeat\u001b[39m(arr: ArrayLike, index: Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m    733\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;124;03m    If we have a length-1 array and an index describing how long we expect\u001b[39;00m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;124;03m    the result to be, repeat the array.\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EXIBINDO OS RESULTADOS\n",
    "# Identifica as posições (índices e colunas) onde há valores faltantes\n",
    "missing_positions = [(row_idx, col_name)\n",
    "                     for row_idx, row in df_inicial.iterrows()\n",
    "                     for col_name, value in row.items()\n",
    "                     if pd.isnull(value)]\n",
    "\n",
    "# Exibe as posições encontradas\n",
    "for pos in missing_positions:\n",
    "    print(f\"Valor faltante na linha {pos[0]}, coluna '{pos[1]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64631511",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb4a6d",
   "metadata": {},
   "source": [
    "### **(c)** Contar quantas linhas possuem valores faltantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea02cf9",
   "metadata": {},
   "source": [
    "Neste item, resolvi calcular não só quantas linhas possuem valores `NaN`, mas também exibir a quantidade total de células faltantes.\n",
    "\n",
    "Este trecho de código identifica valores faltantes utilizando o método `.isnull()`, que retorna um DataFrame booleano, onde `True` indica a presença de um valor faltante. Em seguida, o método `.stack()` é utilizado para transformar as colunas em uma série com um índice multi-nível, facilitando a visualização das posições dos valores faltantes. \n",
    "\n",
    "A variável `missing_positions` filtra apenas as células com valor `True` (ou seja, com valor faltante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6fa5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As 10 primeiras posições com valores faltantes:\n",
      "0  media                   True\n",
      "   media_type              True\n",
      "   media_url               True\n",
      "   score_misinformation    True\n",
      "   media_name              True\n",
      "   media_md5               True\n",
      "1  id_member_anonymous     True\n",
      "   media                   True\n",
      "   media_type              True\n",
      "   media_url               True\n",
      "dtype: bool\n",
      "\n",
      "Total de células com valores faltantes: 2544186\n",
      "\n",
      "Número de linhas com pelo menos um valor faltante: 557561\n"
     ]
    }
   ],
   "source": [
    "# Identifica os valores faltantes com .isnull() e empilha o DataFrame (stack transforma colunas em uma série multi-index)\n",
    "missing = df_inicial.isnull().stack()\n",
    "\n",
    "# Filtra apenas as células com valor faltante (True)\n",
    "missing_positions = missing[missing]\n",
    "\n",
    "# Exibe as 10 primeiras posições com valores faltantes\n",
    "print(\"As 10 primeiras posições com valores faltantes:\")\n",
    "print(missing_positions.head(10))\n",
    "\n",
    "# Exibe o total de células faltantes\n",
    "print(f\"\\nTotal de células com valores faltantes: {missing_positions.shape[0]}\")\n",
    "\n",
    "# Conta quantas linhas possuem pelo menos um valor faltante\n",
    "linhas_com_nulos = df_inicial.isnull().any(axis=1).sum()\n",
    "print(f\"\\nNúmero de linhas com pelo menos um valor faltante: {linhas_com_nulos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be48829",
   "metadata": {},
   "source": [
    "**IMPORTANTE SABER!!**\n",
    "\n",
    "Em um DataFrame, o número total de células é o produto entre o número de linhas e colunas, o que significa que o total de células sempre será maior que o número de linhas. \n",
    "Quando falamos sobre células faltantes, estamos nos referindo a quantas dessas células não possuem valor, e esse número pode ser muito maior que o número de linhas, especialmente se várias colunas tiverem muitos valores ausentes em várias linhas. Portanto, mesmo que o dataset tenha 557.586 registros (linhas), o total de células faltantes pode ser muito maior, dependendo de quantas colunas possuem dados ausentes em suas respectivas linhas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544958ef",
   "metadata": {},
   "source": [
    "### **(d)** Para cada coluna (feature), contar quantas linhas possuem valores faltantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accaa08",
   "metadata": {},
   "source": [
    "A questão pede para contar quantas linhas possuem valores faltantes para cada coluna, o que está sendo solicitado é a quantidade de linhas (ou registros) em que cada coluna possui pelo menos um valor faltante. O proesso adotado para identificar isso foi realizado da seguinte forma:\n",
    "\n",
    "- df_inicial.isnull(): Cria um DataFrame booleano onde True indica um valor faltante e False indica um valor presente.\n",
    "- .sum(axis=0): Conta quantos True existem em cada coluna (ou seja, quantas linhas têm valores faltantes para aquela coluna específica).\n",
    "- missing_lines_per_column.items(): Itera sobre as colunas e o número de valores faltantes em cada uma delas, imprimindo a quantidade de linhas com dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c01b9412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de linhas com pelo menos um valor faltante por coluna:\n",
      "Coluna 'date_message': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'id_member_anonymous': 323,341 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'id_group_anonymous': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'media': 224,981 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'media_type': 224,981 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'media_url': 400,141 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'has_media': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'has_media_url': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'trava_zap': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'text_content_anonymous': 113,385 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'dataset_info_id': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'date_system': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'score_sentiment': 113,429 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'score_misinformation': 390,348 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'id_message': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'message_type': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'messenger': 0 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'media_name': 528,599 linha(s) com valor(es) faltante(s)\n",
      "Coluna 'media_md5': 224,981 linha(s) com valor(es) faltante(s)\n"
     ]
    }
   ],
   "source": [
    "# Conta quantas linhas possuem pelo menos um valor faltante para cada coluna\n",
    "missing_lines_per_column = df_inicial.isnull().sum(axis=0)\n",
    "\n",
    "# Exibe o número de linhas com valores faltantes por coluna\n",
    "print(\"\\nNúmero de linhas com pelo menos um valor faltante por coluna:\")\n",
    "for column, missing_count in missing_lines_per_column.items():\n",
    "    print(f\"Coluna '{column}': {missing_count:,} linha(s) com valor(es) faltante(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026a9fb",
   "metadata": {},
   "source": [
    "### **(e)** Identificar e listar as linhas repetidas (duplicadas). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa67b99",
   "metadata": {},
   "source": [
    "Da mesma forma que usamos `pandas`para identificar e listar valores NaN, podemos utilizá-lo para identificar e tratar dados duplicados utilizando um procedimento chamado `.duplicated()`. Esse método verifica se uma linha é idêntica a uma linha anterior e retorna um Dataframe com valores `True` quando há linhas duplicadas.\n",
    "\n",
    "Além disso, se quisermos considerar uma única coluna para identificar duplicatas, podemos apenas passar o número da coluna durante a chamada do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79d23bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As 10 primeiras linhas duplicadas:\n",
      "Empty DataFrame\n",
      "Columns: [date_message, id_member_anonymous, id_group_anonymous, media, media_type, media_url, has_media, has_media_url, trava_zap, text_content_anonymous, dataset_info_id, date_system, score_sentiment, score_misinformation, id_message, message_type, messenger, media_name, media_md5]\n",
      "Index: []\n",
      "\n",
      "Total de linhas duplicadas: 0\n",
      "\n",
      "Linhas duplicadas (incluindo a primeira ocorrência):\n",
      "Empty DataFrame\n",
      "Columns: [date_message, id_member_anonymous, id_group_anonymous, media, media_type, media_url, has_media, has_media_url, trava_zap, text_content_anonymous, dataset_info_id, date_system, score_sentiment, score_misinformation, id_message, message_type, messenger, media_name, media_md5]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identifica as linhas duplicadas\n",
    "duplicatas = df_inicial[df_inicial.duplicated()]\n",
    "\n",
    "# Exibe as 10 primeiras linhas duplicadas\n",
    "print(\"As 10 primeiras linhas duplicadas:\")\n",
    "print(duplicatas.head(10))\n",
    "\n",
    "# Exibe o número total de linhas duplicadas\n",
    "print(f\"\\nTotal de linhas duplicadas: {duplicatas.shape[0]}\")\n",
    "\n",
    "# Exibe as duplicatas completas (incluindo a primeira ocorrência)\n",
    "duplicatas_completas = df_inicial[df_inicial.duplicated(keep=False)]\n",
    "\n",
    "# Exibe as duplicatas completas\n",
    "print(\"\\nLinhas duplicadas (incluindo a primeira ocorrência):\")\n",
    "print(duplicatas_completas.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69585e",
   "metadata": {},
   "source": [
    "Já que nenhuma linha inteira está duplicada, eu resolvi criar um script para identificar duplicatas por features da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c608dc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coluna 'date_message' - Total de valores duplicados (incluindo repetições): 201714\n",
      "Valores mais comuns duplicados:\n",
      "date_message\n",
      "2022-10-12 16:55:36    62\n",
      "2022-10-30 13:52:37    59\n",
      "2022-10-12 16:55:34    58\n",
      "2022-10-06 12:38:50    53\n",
      "2022-10-06 14:22:13    53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'id_member_anonymous' - Total de valores duplicados (incluindo repetições): 551247\n",
      "Valores mais comuns duplicados:\n",
      "id_member_anonymous\n",
      "abe534d581ec6d552243d6955d3c3cd8    12289\n",
      "1665e22b0f564cd46d343f7677014821     5452\n",
      "1ac091b8ed5c4e42383f1b4ff4cc9b2d     5060\n",
      "c743967449a387ad2c1c7e03b2c45b36     3019\n",
      "e7998863ac2a40086657fab4a6b463c9     1928\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'id_group_anonymous' - Total de valores duplicados (incluindo repetições): 557584\n",
      "Valores mais comuns duplicados:\n",
      "id_group_anonymous\n",
      "5b10d7739171149be6d9961e3350c071    112228\n",
      "857cd5311da1bdc15eb9e6918a47c6c6     76912\n",
      "b8a8737812c7fd7d3e0bdbb65ef6306f     35983\n",
      "e56ec342fc599ebb4ed89655eb6f03aa     35713\n",
      "959f13e0079883060632c74ffc81c547     20565\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'media' - Total de valores duplicados (incluindo repetições): 445448\n",
      "Valores mais comuns duplicados:\n",
      "media\n",
      "b5ab97b82ce9a3957022b7388d8fb910.apk    5473\n",
      "4d60b50f292b14a9d62a0bb2f1b42796.jpg    1847\n",
      "5d4089a914ac6fa7d04cbe08bb8057f5.apk    1481\n",
      "c4266d6971f2e3517f99d5736d8f0f40.jpg    1404\n",
      "baba583ff1a3a79f11ed019cc319f2f2.jpg    1136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'media_type' - Total de valores duplicados (incluindo repetições): 557567\n",
      "Valores mais comuns duplicados:\n",
      "media_type\n",
      "image/jpg                                  200441\n",
      "url                                        100856\n",
      "video/mp4                                   18497\n",
      "application/vnd.android.package-archive      7159\n",
      "application/pdf                              2850\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'media_url' - Total de valores duplicados (incluindo repetições): 522256\n",
      "Valores mais comuns duplicados:\n",
      "media_url\n",
      "t.me/alexeconomia                                  4159\n",
      "https://youtube.com/c/especulandoosfatosoficial    1607\n",
      "t.me/fimtaproximo                                  1581\n",
      "t.me/+EWlGMatRZGg3OTlh                             1419\n",
      "https://youtu.be/qbTzhB0akt8                       1160\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'has_media' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "has_media\n",
      "True     332605\n",
      "False    224981\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'has_media_url' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "has_media_url\n",
      "False    400141\n",
      "True     157445\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'trava_zap' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "trava_zap\n",
      "False    557570\n",
      "True         16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'text_content_anonymous' - Total de valores duplicados (incluindo repetições): 339922\n",
      "Valores mais comuns duplicados:\n",
      "text_content_anonymous\n",
      "This community was blocked in Brazil following a decision of the Superior Electoral Court (TSE).                                                                                                                                                                                                                                                                         17422\n",
      "Rough_sex🙈                                                                                                                                                                                                                                                                                                                                                                1134\n",
      "Anal sex🙈                                                                                                                                                                                                                                                                                                                                                                 1118\n",
      "سکس مردان ازبک با زن انگلیسی با این vpn از سایتهای ممنوعه ببینید🙈\\n\\nشاهد الرجال الأوزبكيين يمارسون الجنس مع النساء الإنجليزيات باستخدام VPN هذا من المواقع المحظورة🚫\\n\\nTaqiqlangan saytlardan bu vpn orqali o'zbek erkaklari ingliz ayollari bilan jinsiy aloqa qilishlarini ko'ring\\n\\nSee Uzbek men having sex with English women with this vpn from banned sites     1019\n",
      "https://youtu.be/qbTzhB0akt8                                                                                                                                                                                                                                                                                                                                               758\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'dataset_info_id' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "dataset_info_id\n",
      "5    557586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'date_system' - Nenhum valor duplicado encontrado.\n",
      "\n",
      "Coluna 'score_sentiment' - Total de valores duplicados (incluindo repetições): 555587\n",
      "Valores mais comuns duplicados:\n",
      "score_sentiment\n",
      " 0.0000    179968\n",
      " 0.5423     18247\n",
      "-0.1531      8977\n",
      "-0.2960      7740\n",
      " 0.7096      5923\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'score_misinformation' - Total de valores duplicados (incluindo repetições): 476706\n",
      "Valores mais comuns duplicados:\n",
      "score_misinformation\n",
      "0.110628    1019\n",
      "0.064152     632\n",
      "0.018844     585\n",
      "0.158725     480\n",
      "0.023719     469\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'id_message' - Total de valores duplicados (incluindo repetições): 251533\n",
      "Valores mais comuns duplicados:\n",
      "id_message\n",
      "1023    18\n",
      "1031    18\n",
      "1396    18\n",
      "1614    18\n",
      "1012    18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'message_type' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "message_type\n",
      "Texto          224981\n",
      "Imagem         202762\n",
      "Url            100856\n",
      "Video           18631\n",
      "Application     10168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'messenger' - Total de valores duplicados (incluindo repetições): 557586\n",
      "Valores mais comuns duplicados:\n",
      "messenger\n",
      "telegram    557586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'media_name' - Total de valores duplicados (incluindo repetições): 547568\n",
      "Valores mais comuns duplicados:\n",
      "media_name\n",
      "سکس زوری.apk        2723\n",
      "سک.س از ک.ون.apk    1836\n",
      "لزبین.apk            991\n",
      "سکس خفن.apk          651\n",
      "س.کس خشن.apk         476\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Coluna 'media_md5' - Total de valores duplicados (incluindo repetições): 441471\n",
      "Valores mais comuns duplicados:\n",
      "media_md5\n",
      "b5ab97b82ce9a3957022b7388d8fb910    5480\n",
      "4d60b50f292b14a9d62a0bb2f1b42796    1868\n",
      "5d4089a914ac6fa7d04cbe08bb8057f5    1481\n",
      "c4266d6971f2e3517f99d5736d8f0f40    1419\n",
      "baba583ff1a3a79f11ed019cc319f2f2    1151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Para cada coluna, identifica e exibe os valores duplicados e sua contagem\n",
    "for coluna in df_inicial.columns:\n",
    "    duplicados = df_inicial[coluna][df_inicial[coluna].duplicated(keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(f\"\\nColuna '{coluna}' - Total de valores duplicados (incluindo repetições): {duplicados.shape[0]}\")\n",
    "        print(\"Valores mais comuns duplicados:\")\n",
    "        print(duplicados.value_counts().head(5))  # Mostra os 5 valores duplicados mais comuns\n",
    "    else:\n",
    "        print(f\"\\nColuna '{coluna}' - Nenhum valor duplicado encontrado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25920674",
   "metadata": {},
   "source": [
    "Para fins de compreensão da análise, é possível tirar as seguintes conclusões:\n",
    "- Coluna `data_message`:\n",
    "    - Duplicados: 201.714 datas repetidas.\n",
    "    - Indica que muitas mensagens foram enviadas no mesmo segundo, então faz sentido dado que nosso dataset trabalha com grupos de mensagem com muitos membros.\n",
    "- Coluna `id_member_anonymous`:\n",
    "    - Duplicados: 551.247 ocorrências repetidas.\n",
    "    - Mostra que um mesmo usário enviou várias mensagens.\n",
    "    - Por exemplo, teve um único usuário que enviou aproximadamente 12 mil mensagens.\n",
    "- Coluna `id_group_anonymous`:\n",
    "    - Duplicados: 557.584 repetições\n",
    "    - Indica que muitas mensagens vieram dos mesmos grupos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7512cf",
   "metadata": {},
   "source": [
    "### **(f)** Identificar e listar as posições (células) contendo valores que não pertencem ao domínio (tipo de dados) esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af95168",
   "metadata": {},
   "source": [
    "Para realizar essa identificação, vamos seguir um conjunto de passos para tornar a análise mais organizada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787afccb",
   "metadata": {},
   "source": [
    "#### **Passo 01**\n",
    "Inspeção dos tipos das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5357717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de dados das colunas:\n",
      "date_message               object\n",
      "id_member_anonymous        object\n",
      "id_group_anonymous         object\n",
      "media                      object\n",
      "media_type                 object\n",
      "media_url                  object\n",
      "has_media                    bool\n",
      "has_media_url                bool\n",
      "trava_zap                    bool\n",
      "text_content_anonymous     object\n",
      "dataset_info_id             int64\n",
      "date_system                object\n",
      "score_sentiment           float64\n",
      "score_misinformation      float64\n",
      "id_message                  int64\n",
      "message_type               object\n",
      "messenger                  object\n",
      "media_name                 object\n",
      "media_md5                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de dados das colunas:\")\n",
    "print(df_inicial.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22821fc6",
   "metadata": {},
   "source": [
    "#### **Passo 02**\n",
    "Agora, vamos analisar as estatísticas gerais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffb4cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estatísticas descritivas (colunas numéricas):\n",
      "       dataset_info_id  score_sentiment  score_misinformation    id_message\n",
      "count         557586.0    444157.000000         167238.000000  5.575860e+05\n",
      "mean               5.0         0.017330              0.312245  4.450617e+05\n",
      "std                0.0         0.464165              0.293699  4.860211e+05\n",
      "min                5.0        -1.000000              0.000003  2.000000e+00\n",
      "25%                5.0        -0.177900              0.078454  2.127500e+04\n",
      "50%                5.0         0.000000              0.197577  1.210935e+05\n",
      "75%                5.0         0.318200              0.490351  9.726045e+05\n",
      "max                5.0         0.999200              1.000000  1.516436e+06\n",
      "\n",
      "Estatísticas descritivas (colunas categóricas):\n",
      "               date_message               id_member_anonymous  \\\n",
      "count                557586                            234245   \n",
      "unique               430133                             14809   \n",
      "top     2022-10-12 16:55:36  abe534d581ec6d552243d6955d3c3cd8   \n",
      "freq                     62                             12289   \n",
      "\n",
      "                      id_group_anonymous  \\\n",
      "count                             557586   \n",
      "unique                               178   \n",
      "top     5b10d7739171149be6d9961e3350c071   \n",
      "freq                              112228   \n",
      "\n",
      "                                       media media_type          media_url  \\\n",
      "count                                 332605     332605             157445   \n",
      "unique                                163503         67              56552   \n",
      "top     b5ab97b82ce9a3957022b7388d8fb910.apk  image/jpg  t.me/alexeconomia   \n",
      "freq                                    5473     200441               4159   \n",
      "\n",
      "                                   text_content_anonymous  \\\n",
      "count                                              444201   \n",
      "unique                                             265326   \n",
      "top     This community was blocked in Brazil following...   \n",
      "freq                                                17422   \n",
      "\n",
      "                       date_system message_type messenger    media_name  \\\n",
      "count                       557586       557586    557586         28987   \n",
      "unique                      557586            8         1         13787   \n",
      "top     2022-10-05 06:25:28.863641        Texto  telegram  سکس زوری.apk   \n",
      "freq                             1       224981    557586          2723   \n",
      "\n",
      "                               media_md5  \n",
      "count                             332605  \n",
      "unique                            164864  \n",
      "top     b5ab97b82ce9a3957022b7388d8fb910  \n",
      "freq                                5480  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEstatísticas descritivas (colunas numéricas):\")\n",
    "print(df_inicial.describe())\n",
    "\n",
    "print(\"\\nEstatísticas descritivas (colunas categóricas):\")\n",
    "print(df_inicial.describe(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4a411",
   "metadata": {},
   "source": [
    "#### **Passo 03**\n",
    "Elaborando as regras de domínio esperadas, visto que precisamos definir o que é esperado para cada coluna, com base nos tipos e contexto dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd10eb",
   "metadata": {},
   "source": [
    "\n",
    "Usando a biblioteca `numpy` porque ela fornece tipos de dados eficientes e funções robustas para verificação de valores, como distinguir corretamente entre inteiros, floats e booleanos, mesmo quando os dados vêm de fontes ambíguas (como arquivos CSV, onde tudo pode ser lido como string). \n",
    "\n",
    "Verificar se os valores estão dentro do domínio esperado é fundamental para garantir a integridade dos dados: valores fora do intervalo válido ou com tipo incorreto podem comprometer análises estatísticas, modelos de machine learning ou a própria compreensão do fenômeno estudado. Esse passo assegura que os dados sejam consistentes e confiáveis para as etapas seguintes da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "338f92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8b5537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna media_type:\n",
      "[nan 'image/jpg' 'video/mp4' 'url' 'image/mp4' 'audio/opus' 'image/pdf'\n",
      " 'application/pdf' 'video/webm' 'image/webm' 'image/apk'\n",
      " 'application/vnd.android.package-archive' 'application/octet-stream'\n",
      " 'video/quicktime' 'application/zip' 'video/mpeg'\n",
      " 'image/59da33c80babcbb29455fccb21329cae' 'text/x-vcard' 'video/3gpp'\n",
      " 'image/mpv' 'video/x-matroska' 'image/mpeg' 'image/mov'\n",
      " 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n",
      " 'audio/aac' 'image/7f9d809d82c2545a2dc8160d5015c8ad' 'audio/mpeg'\n",
      " 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
      " 'image/wma' 'audio/x-ms-wma' 'image/mp3' 'text/html' 'video/x-ms-wmv'\n",
      " 'application/vnd.ms-xpsdocument' 'image/xps' 'application/json'\n",
      " 'application/gzip' 'audio/ogg' 'image/gif'\n",
      " 'application/x-partial-download' 'image/jpeg' 'image/heic'\n",
      " 'application/x-ms-dos-executable' 'image/oga'\n",
      " 'image/f733407db79a2b74eff03a89529e5d57'\n",
      " 'image/b39768873845aaea0f8ab41b2e9c0061' 'image/msi'\n",
      " 'image/02d0e99ce96591d1e3d354ebb0690607' 'application/x-msi'\n",
      " 'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n",
      " 'image/08e8201b6f32c358808c7ac89d8c8422' 'application/x-mimearchive'\n",
      " 'video/x-flv' 'image/wmv' 'image/flv'\n",
      " 'image/45dbf1564a99d025ade111ea1dd2add5' 'application/sdoc' 'image/adts'\n",
      " 'audio/x-wav' 'image/wav' 'image/m4a' 'audio/m4a' 'image/f4v' 'image/gz'\n",
      " 'image/xlsx' 'image/af75130da3b6516eb3c1eb9ab62b5219'\n",
      " 'application/binary' 'image/b0cf97975368a5ebec0eb3d25e695e1c']\n",
      "Contagem de valores na coluna media_type:\n",
      "media_type\n",
      "image/jpg                                  200441\n",
      "url                                        100856\n",
      "video/mp4                                   18497\n",
      "application/vnd.android.package-archive      7159\n",
      "application/pdf                              2850\n",
      "                                            ...  \n",
      "audio/x-ms-wma                                  1\n",
      "image/wma                                       1\n",
      "image/7f9d809d82c2545a2dc8160d5015c8ad          1\n",
      "text/x-vcard                                    1\n",
      "image/b0cf97975368a5ebec0eb3d25e695e1c          1\n",
      "Name: count, Length: 67, dtype: int64\n",
      "\n",
      "\n",
      "Valores únicos na coluna message_type:\n",
      "['Texto' 'Imagem' 'Video' 'Url' 'Audio' 'Application' 'Text' 'Image']\n",
      "Contagem de valores na coluna message_type:\n",
      "message_type\n",
      "Texto          224981\n",
      "Imagem         202762\n",
      "Url            100856\n",
      "Video           18631\n",
      "Application     10168\n",
      "Audio             177\n",
      "Image               8\n",
      "Text                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Valores únicos na coluna messenger:\n",
      "['telegram']\n",
      "Contagem de valores na coluna messenger:\n",
      "messenger\n",
      "telegram    557586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análise exploratória dos valores nas colunas categóricas\n",
    "for col in ['media_type', 'message_type', 'messenger']:\n",
    "    print(f\"Valores únicos na coluna {col}:\")\n",
    "    print(df_inicial[col].unique())\n",
    "    print(f\"Contagem de valores na coluna {col}:\")\n",
    "    print(df_inicial[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão de datas\n",
    "df_inicial['date_message'] = pd.to_datetime(df_inicial['date_message'], errors='coerce')\n",
    "df_inicial['date_system'] = pd.to_datetime(df_inicial['date_system'], errors='coerce')\n",
    "\n",
    "# Normalização de colunas categóricas\n",
    "colunas_categoricas = ['media_type', 'message_type', 'messenger']\n",
    "for col in colunas_categoricas:\n",
    "    df_inicial[col] = df_inicial[col].astype(str).str.lower().str.strip().replace({'nan': np.nan})\n",
    "\n",
    "# Lista para armazenar violações\n",
    "violacoes = []\n",
    "\n",
    "# Loop de validação\n",
    "for idx, row in df_inicial.iterrows():\n",
    "    # score_sentiment: deve estar entre -1 e 1\n",
    "    s = row['score_sentiment']\n",
    "    if pd.notnull(s) and (s < -1 or s > 1):\n",
    "        violacoes.append((idx, 'score_sentiment', s))\n",
    "\n",
    "    # score_misinformation: deve estar entre 0 e 1\n",
    "    m = row['score_misinformation']\n",
    "    if pd.notnull(m) and (m < 0 or m > 1):\n",
    "        violacoes.append((idx, 'score_misinformation', m))\n",
    "\n",
    "    # dataset_info_id: deve ser exatamente 5\n",
    "    d = row['dataset_info_id']\n",
    "    if d != 5:\n",
    "        violacoes.append((idx, 'dataset_info_id', d))\n",
    "\n",
    "    # id_message: deve ser inteiro positivo\n",
    "    im = row['id_message']\n",
    "    if not isinstance(im, (int, np.integer)) or im < 0:\n",
    "        violacoes.append((idx, 'id_message', im))\n",
    "\n",
    "    # Datas válidas\n",
    "    if pd.isnull(row['date_message']):\n",
    "        violacoes.append((idx, 'date_message', 'data inválida'))\n",
    "    if pd.isnull(row['date_system']):\n",
    "        violacoes.append((idx, 'date_system', 'data inválida'))\n",
    "\n",
    "    # Colunas booleanas\n",
    "    for col in ['has_media', 'has_media_url', 'trava_zap']:\n",
    "        if not isinstance(row[col], (bool, np.bool_)):\n",
    "            violacoes.append((idx, col, row[col]))\n",
    "\n",
    "    # Verificação se as colunas categóricas são do tipo string (objeto válido)\n",
    "    for col in colunas_categoricas:\n",
    "        val = row[col]\n",
    "        if pd.notnull(val) and not isinstance(val, str):\n",
    "            violacoes.append((idx, col, val))\n",
    "\n",
    "# Resultado\n",
    "print(f\"Total de violações de tipo categórico: {len(violacoes)}\")\n",
    "for v in violacoes[:10]:\n",
    "    print(f\"Violação na linha {v[0]}, coluna '{v[1]}': valor '{v[2]}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d658ab",
   "metadata": {},
   "source": [
    "A forma como definimos o domínio de uma feature, baseando-se em análise anteriores dos dados, pode ocasionar ou não em violações. No códifo em questão, ele foi editado várias vezes com o objetivo de entender as violações que estavam sendo consideradas e se elas realmente faziam sentido dado a feature estudada.\n",
    "\n",
    "Lembrando que, realizar a validação dessa forma foi uma escolha minha, mesmo sabendo que existem outras formas mais fáceis de validar, sem precisar necessariamente de um conjunto pré-definido. Essa escolhafoi feita apenas para ter certeza de que as features object não estavam com dados diferentes do esperado e eu poderia fazer um .unique() para capturar todos os valores existentes nessas colunas em específico.\n",
    "\n",
    "Este código garante que dados como datas, valores booleanos e pontuações estejam consistentes com suas definições, ajudando a identificar erros que poderiam comprometer a análise posterior.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef0f10",
   "metadata": {},
   "source": [
    "### **(g)** Crie uma coluna chamada “caracteres” contendo a quantidade de caracteres da coluna “text”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb837ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTANDO NOVAMENTE AS COLUNAS DO DATABASE APENAS PARA FICAR MAIS FÁCIL DE VISUALIZAR\n",
    "list(df_inicial.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920881f0",
   "metadata": {},
   "source": [
    "Para resolver este item, podemos seguir alguns passos importantes. Mesmo sabendo que a coluna `text_content_anonymous` existe, é importante fazer uma verificação inicial de que ela faz parte do nosso database.\n",
    "\n",
    "Depois disso, é necessário dar uma atenção especial aos valores faltantes, isto é, verificar se faz sentido converter valores `NaN`para string vazia ou deixá-los dessa forma. Depois, podemos apenas criar a coluna `caracteres` utilizando o que aprendemos em sala de aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a955c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text_content_anonymous  caracteres\n",
      "442837                                                NaN           0\n",
      "495617        https://www.youtube.com/watch?v=wzJ5cV69OsA          43\n",
      "504220  A INACREDITÁVEL CENSURA ÀS FALAS DE CARLA CECA...         299\n",
      "251559  No \"apagar das luzes\", Daniel Silveira dispara...          66\n",
      "520667                                                NaN           0\n"
     ]
    }
   ],
   "source": [
    "# Criação da coluna 'caracteres' com a quantidade de caracteres da coluna 'text_content_anonymous'\n",
    "df_inicial['caracteres'] = df_inicial['text_content_anonymous'].apply(\n",
    "    lambda x: len(str(x)) if pd.notnull(x) else 0\n",
    ")\n",
    "\n",
    "# Exibição de uma amostra aleatória para conferência\n",
    "print(df_inicial[['text_content_anonymous', 'caracteres']].sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a33c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96a629",
   "metadata": {},
   "source": [
    "### **(h)** Crie uma coluna chamada “words” contendo a quantidade de palavras da coluna “text”. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c14cd6",
   "metadata": {},
   "source": [
    "Mesma coisa do item anterior, mas vamos utilizar o `.split()` que separa a string em uma lista de palavras com base em espaços."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcabaa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text_content_anonymous  words\n",
      "442837                                                NaN      0\n",
      "495617        https://www.youtube.com/watch?v=wzJ5cV69OsA      1\n",
      "504220  A INACREDITÁVEL CENSURA ÀS FALAS DE CARLA CECA...     25\n",
      "251559  No \"apagar das luzes\", Daniel Silveira dispara...     12\n",
      "520667                                                NaN      0\n"
     ]
    }
   ],
   "source": [
    "df_inicial['words'] = df_inicial['text_content_anonymous'].apply(\n",
    "    lambda x: len(str(x).split()) if pd.notnull(x) else 0\n",
    ")\n",
    "\n",
    "print(df_inicial[['text_content_anonymous', 'words']].sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26673c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ba584",
   "metadata": {},
   "source": [
    "### **(i)**  Crie uma coluna chamada “viral” contendo o valor 0 se o texto da mensagem (valor do campo “text”) não for encontrado em outras linhas e 1, caso contrário. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb9630",
   "metadata": {},
   "source": [
    "Basicamente, vamos utilizar os mesmos conhecimentos aplicados para identificar e listar duplicatas. Para isso, utilizei o método `duplicated(keep=False)`, que marca como `True` todas as ocorrências de valores repetidos (não apenas as subsequentes). Em seguida, converti o resultado para inteiro (`1` para mensagens virais, `0` para únicas). Também tratei os valores ausentes da coluna `text_content_anonymous` como **não virais**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d6d16c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text_content_anonymous  viral\n",
      "442837                                                NaN      0\n",
      "495617        https://www.youtube.com/watch?v=wzJ5cV69OsA      0\n",
      "504220  A INACREDITÁVEL CENSURA ÀS FALAS DE CARLA CECA...      1\n",
      "251559  No \"apagar das luzes\", Daniel Silveira dispara...      0\n",
      "520667                                                NaN      0\n"
     ]
    }
   ],
   "source": [
    "df_inicial['viral'] = df_inicial['text_content_anonymous'].duplicated(keep=False)\n",
    "df_inicial['viral'] = df_inicial['viral'].where(df_inicial['text_content_anonymous'].notna(), 0).astype(int)\n",
    "\n",
    "print(df_inicial[['text_content_anonymous', 'viral']].sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdeeb1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afe2c7",
   "metadata": {},
   "source": [
    "### **(j)** Crie uma coluna chamada “sharings” contendo a quantidade de vezes que o texto armazenado no atributo “text” aparece no dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e97980",
   "metadata": {},
   "source": [
    "Para criar a coluna `sharings`, utilizei a função `groupby().transform('count')` sobre a variável `text_content_anonymous`. Essa abordagem permite contar quantas vezes cada texto aparece no dataset, atribuindo esse número à nova coluna para todas as linhas com o mesmo conteúdo. Também tratei os valores ausentes (`NaN`), substituindo seus compartilhamentos por 0, já que não representam mensagens válidas a serem compartilhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c49b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inicial['sharings'] = df_inicial.groupby('text_content_anonymous')['text_content_anonymous'].transform('count')\n",
    "\n",
    "# textos ausentes (NaN) tratados como 0 compartilhamentos\n",
    "df_inicial['sharings'] = df_inicial['sharings'].where(df_inicial['text_content_anonymous'].notna(), 0)\n",
    "\n",
    "print(df_inicial[['text_content_anonymous', 'sharings']].sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed5920",
   "metadata": {},
   "source": [
    "### **(k)**  Crie uma coluna chamada “sentiment” contendo os valores: -1 para textos negativos, 0 para textos neutros e 1 para textos positivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17fcba",
   "metadata": {},
   "source": [
    "Para criar a coluna sentiment, utilizei uma coluna já existente no database: `score_sentiment` onde o sentimento já foi pré-computado e muito provavelmente representa a polaridade de cada texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cd5641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               text_content_anonymous  score_sentiment\n",
      "0   Então é Fato Renato o áudio que eu ouvi no wha...           0.0000\n",
      "1   Saiu no YouTube do presidente a 8 horas atrás,...           0.0644\n",
      "2   É isso, nossa parte já foi quase toda feita. N...          -0.3551\n",
      "3            GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA           0.0000\n",
      "4                                                 NaN              NaN\n",
      "5   Kķkkkkk to rindo até agora....Quem disse q ia ...           0.7003\n",
      "6   *SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...           0.9716\n",
      "7                                                 NaN              NaN\n",
      "8                                                 NaN              NaN\n",
      "9   O Deputado Federal pelo NOVO e que foi candida...          -0.8779\n",
      "10  Saiam desse grupo amigos bolsonaristas, urgent...          -0.9423\n",
      "11  Gazprom da Rússia: Retomamos o fornecimento de...          -0.1531\n",
      "12  Saiam desse grupo amigos bolsonaristas, urgent...          -0.9596\n",
      "13  Saiam desse grupo amigos bolsonaristas, urgent...          -0.9423\n",
      "14  Saiam desse grupo amigos bolsonaristas, urgent...          -0.9596\n"
     ]
    }
   ],
   "source": [
    "# ANALISANDO AS PRIMEIRAS 15 LINHAS PARA VER COMO OS DADOS ESTÃO VINDO\n",
    "print(df_inicial[['text_content_anonymous', 'score_sentiment']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f943ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               text_content_anonymous  score_sentiment  \\\n",
      "0   Então é Fato Renato o áudio que eu ouvi no wha...            0.000   \n",
      "1   Saiu no YouTube do presidente a 8 horas atrás,...            0.064   \n",
      "2   É isso, nossa parte já foi quase toda feita. N...           -0.355   \n",
      "3            GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA            0.000   \n",
      "5   Kķkkkkk to rindo até agora....Quem disse q ia ...            0.700   \n",
      "6   *SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...            0.972   \n",
      "9   O Deputado Federal pelo NOVO e que foi candida...           -0.878   \n",
      "10  Saiam desse grupo amigos bolsonaristas, urgent...           -0.942   \n",
      "11  Gazprom da Rússia: Retomamos o fornecimento de...           -0.153   \n",
      "12  Saiam desse grupo amigos bolsonaristas, urgent...           -0.960   \n",
      "\n",
      "    sentiment  \n",
      "0         0.0  \n",
      "1         1.0  \n",
      "2        -1.0  \n",
      "3         0.0  \n",
      "5         1.0  \n",
      "6         1.0  \n",
      "9        -1.0  \n",
      "10       -1.0  \n",
      "11       -1.0  \n",
      "12       -1.0  \n"
     ]
    }
   ],
   "source": [
    "# FUNÇÃO PARA CLASSIFICAR POLARIDADES\n",
    "def classificar_sentimento(score):\n",
    "    if pd.isna(score):\n",
    "        return None \n",
    "    elif score >= 0.05:\n",
    "        return 1\n",
    "    elif score <= -0.05:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Aplica a função\n",
    "df_inicial['sentiment'] = df_inicial['score_sentiment'].apply(classificar_sentimento)\n",
    "\n",
    "# Arredonda a coluna score_sentiment para 3 casas decimais (apenas para visualização)\n",
    "df_inicial['score_sentiment'] = df_inicial['score_sentiment'].round(3)\n",
    "\n",
    "# Mostra 10 exemplos com texto, score e sentimento\n",
    "print(df_inicial[['text_content_anonymous', 'score_sentiment', 'sentiment']].dropna().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af87c2",
   "metadata": {},
   "source": [
    "### **(l)** Eliminar as linhas cujo valor da coluna “text” contenham “trava-zaps”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b580a",
   "metadata": {},
   "source": [
    "Criei um novo DataFrame chamado `df_final` a partir do df_inicial para garantir que a exclusão das linhas contendo o termo \"trava-zaps\" na coluna \"text_content_anonymous\" seja feita de forma controlada, sem afetar os dados originais. \n",
    "\n",
    "Dessa forma, consigo preservar a integridade do df_inicial para futuras análises ou verificações, ao mesmo tempo em que manipulo o df_final para as etapas seguintes do processo. Essa abordagem também ajuda a evitar problemas no caso de precisar reverter ou comparar as transformações feitas, proporcionando maior flexibilidade e segurança no tratamento dos dados.\n",
    "\n",
    "Como já analisado, existe uma coluna chamada `trava-zap` no database e, para entender se ela será útil ou não para remoção dessas linhas, realizei um print nas 10 primeiras linhas dessa colunas, mas eu também poderia apenas fazer um `.dtype` e analisar como essa coluna se comporta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15e73c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: trava_zap, dtype: bool\n",
      "[False  True]\n"
     ]
    }
   ],
   "source": [
    "print(df_inicial['trava_zap'].head(10))\n",
    "\n",
    "# Verifica os valores únicos da coluna 'trava_zap'\n",
    "valores_unicos = df_inicial['trava_zap'].unique()\n",
    "\n",
    "# Exibe os valores únicos\n",
    "print(valores_unicos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3bb7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas removidas: 16\n",
      "Linhas removidas:\n",
      "              date_message               id_member_anonymous  \\\n",
      "21944  2022-10-07 07:46:52                               NaN   \n",
      "89109  2022-10-16 00:45:02  8a30ac374bc4b5930eaf0667a178546a   \n",
      "294541 2022-10-04 14:22:47  39ee10516124280a22f1798f2a41f9a7   \n",
      "324567 2022-10-25 14:55:55  e003fbb6ffedb1838e42360d41cab314   \n",
      "389164 2022-10-30 20:19:52                               NaN   \n",
      "423083 2022-11-03 00:40:23                               NaN   \n",
      "466735 2022-11-07 20:47:35  4a498818da925377eff2606a260cfa45   \n",
      "467297 2022-11-08 10:07:14  4a498818da925377eff2606a260cfa45   \n",
      "471273 2022-11-08 20:37:52  4a498818da925377eff2606a260cfa45   \n",
      "478270 2022-11-09 19:50:12  4a498818da925377eff2606a260cfa45   \n",
      "483425 2022-11-10 02:28:43  4a498818da925377eff2606a260cfa45   \n",
      "489757 2022-11-10 20:55:00  4a498818da925377eff2606a260cfa45   \n",
      "489758 2022-11-10 20:55:01  4a498818da925377eff2606a260cfa45   \n",
      "492781 2022-11-11 09:50:37  4a498818da925377eff2606a260cfa45   \n",
      "493561 2022-11-09 06:37:51  4a498818da925377eff2606a260cfa45   \n",
      "493663 2022-11-09 07:48:24                               NaN   \n",
      "\n",
      "                      id_group_anonymous  \\\n",
      "21944   c712c1b704c22bd0cef50bc06125cdbd   \n",
      "89109   e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "294541  959f13e0079883060632c74ffc81c547   \n",
      "324567  5b10d7739171149be6d9961e3350c071   \n",
      "389164  c8f2de56550ed0bf85249608b7ead93d   \n",
      "423083  4d3712f5a117e36180d4b4cbd07c540e   \n",
      "466735  f61777908059b318385882ff47b15c33   \n",
      "467297  f61777908059b318385882ff47b15c33   \n",
      "471273  f61777908059b318385882ff47b15c33   \n",
      "478270  f61777908059b318385882ff47b15c33   \n",
      "483425  f61777908059b318385882ff47b15c33   \n",
      "489757  f61777908059b318385882ff47b15c33   \n",
      "489758  f61777908059b318385882ff47b15c33   \n",
      "492781  f61777908059b318385882ff47b15c33   \n",
      "493561  f61777908059b318385882ff47b15c33   \n",
      "493663  a26d427bec046513e600d165e98660ae   \n",
      "\n",
      "                                       media media_type media_url  has_media  \\\n",
      "21944                                    NaN        NaN       NaN      False   \n",
      "89109                                    NaN        NaN       NaN      False   \n",
      "294541                                   NaN        NaN       NaN      False   \n",
      "324567                                   NaN        NaN       NaN      False   \n",
      "389164                                   NaN        NaN       NaN      False   \n",
      "423083                                   NaN        NaN       NaN      False   \n",
      "466735                                   NaN        NaN       NaN      False   \n",
      "467297                                   NaN        NaN       NaN      False   \n",
      "471273                                   NaN        NaN       NaN      False   \n",
      "478270                                   NaN        NaN       NaN      False   \n",
      "483425                                   NaN        NaN       NaN      False   \n",
      "489757                                   NaN        NaN       NaN      False   \n",
      "489758                                   NaN        NaN       NaN      False   \n",
      "492781                                   NaN        NaN       NaN      False   \n",
      "493561                                   NaN        NaN       NaN      False   \n",
      "493663  d4c34e18a0d3fc82051327e81f0afa7a.jpg  image/jpg       NaN       True   \n",
      "\n",
      "        has_media_url  trava_zap text_content_anonymous  ...  \\\n",
      "21944           False       True                    NaN  ...   \n",
      "89109           False       True                    NaN  ...   \n",
      "294541          False       True                    NaN  ...   \n",
      "324567          False       True                    NaN  ...   \n",
      "389164          False       True                    NaN  ...   \n",
      "423083          False       True                    NaN  ...   \n",
      "466735          False       True                    NaN  ...   \n",
      "467297          False       True                    NaN  ...   \n",
      "471273          False       True                    NaN  ...   \n",
      "478270          False       True                    NaN  ...   \n",
      "483425          False       True                    NaN  ...   \n",
      "489757          False       True                    NaN  ...   \n",
      "489758          False       True                    NaN  ...   \n",
      "492781          False       True                    NaN  ...   \n",
      "493561          False       True                    NaN  ...   \n",
      "493663          False       True                    NaN  ...   \n",
      "\n",
      "        score_misinformation id_message  message_type  messenger  media_name  \\\n",
      "21944               0.067344      53260         texto   telegram         NaN   \n",
      "89109               0.056698     521324         texto   telegram         NaN   \n",
      "294541              0.010433      27241         texto   telegram         NaN   \n",
      "324567              0.403945    1182938         texto   telegram         NaN   \n",
      "389164                   NaN      28330         texto   telegram         NaN   \n",
      "423083              0.067026     171104         texto   telegram         NaN   \n",
      "466735              0.036173      88890         texto   telegram         NaN   \n",
      "467297              0.072637      88977         texto   telegram         NaN   \n",
      "471273              0.031973      89039         texto   telegram         NaN   \n",
      "478270              0.029651      89212         texto   telegram         NaN   \n",
      "483425              0.069928      89295         texto   telegram         NaN   \n",
      "489757              0.223162      89499         texto   telegram         NaN   \n",
      "489758                   NaN      89500         texto   telegram         NaN   \n",
      "492781              0.047049      89642         texto   telegram         NaN   \n",
      "493561              0.095744      89154         texto   telegram         NaN   \n",
      "493663              0.183286       6276        imagem   telegram         NaN   \n",
      "\n",
      "                               media_md5 caracteres words viral  sentiment  \n",
      "21944                                NaN          0     0     0        0.0  \n",
      "89109                                NaN          0     0     0        0.0  \n",
      "294541                               NaN          0     0     0        1.0  \n",
      "324567                               NaN          0     0     0        1.0  \n",
      "389164                               NaN          0     0     0        0.0  \n",
      "423083                               NaN          0     0     0        0.0  \n",
      "466735                               NaN          0     0     0        0.0  \n",
      "467297                               NaN          0     0     0        0.0  \n",
      "471273                               NaN          0     0     0        0.0  \n",
      "478270                               NaN          0     0     0        0.0  \n",
      "483425                               NaN          0     0     0        0.0  \n",
      "489757                               NaN          0     0     0        0.0  \n",
      "489758                               NaN          0     0     0        0.0  \n",
      "492781                               NaN          0     0     0        0.0  \n",
      "493561                               NaN          0     0     0        0.0  \n",
      "493663  d4c34e18a0d3fc82051327e81f0afa7a          0     0     0        0.0  \n",
      "\n",
      "[16 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verifica o número de linhas antes da remoção\n",
    "num_linhas_antes = len(df_inicial)\n",
    "\n",
    "# Identifica as linhas que serão removidas\n",
    "linhas_removidas = df_inicial[df_inicial['trava_zap'] == True]\n",
    "\n",
    "# Filtra apenas as linhas onde 'trava_zap' é False\n",
    "df_inicial = df_inicial[df_inicial['trava_zap'] == False]\n",
    "\n",
    "# Verifica o número de linhas após a remoção\n",
    "num_linhas_depois = len(df_inicial)\n",
    "\n",
    "# Mostra quantas linhas foram removidas\n",
    "print(f'Número de linhas removidas: {num_linhas_antes - num_linhas_depois}')\n",
    "\n",
    "# Exibe as linhas removidas\n",
    "print(\"Linhas removidas:\")\n",
    "print(linhas_removidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a56da0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas: 557570\n",
      "Número de colunas: 23\n",
      "Nome das colunas: Index(['date_message', 'id_member_anonymous', 'id_group_anonymous', 'media',\n",
      "       'media_type', 'media_url', 'has_media', 'has_media_url', 'trava_zap',\n",
      "       'text_content_anonymous', 'dataset_info_id', 'date_system',\n",
      "       'score_sentiment', 'score_misinformation', 'id_message', 'message_type',\n",
      "       'messenger', 'media_name', 'media_md5', 'caracteres', 'words', 'viral',\n",
      "       'sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# PARA MELHOR VISUALIZAÇÃO\n",
    "print(\"Número de linhas:\", df_inicial.shape[0])\n",
    "print(\"Número de colunas:\", df_inicial.shape[1])\n",
    "print(\"Nome das colunas:\", df_inicial.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c17482",
   "metadata": {},
   "source": [
    "### **(m)** Identificar inconsistências entre os atributos (features). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e9687",
   "metadata": {},
   "source": [
    "Durante a análise do dataset, é fundamental identificar e corrigir possíveis inconsistências entre os atributos, considerando as dependências entre as features. \n",
    "\n",
    "Primeiro, é necessário verificar valores nulos nas colunas, decidindo se vamos preencher com valores padrões ou remover as linhas/colunas. Em seguida, devemos identificar duplicatas, garantindo que cada entrada seja única. \n",
    "\n",
    "A verificação de tipos de dados já foi feita em itens anteriores, mas é sempre importante garantir que os tipos estejam corretos, como no caso das colunas de data ou booleanas. Outra análise essencial é a consistência entre colunas relacionadas, como por exemplo, se `has_media` for `True`, as colunas `media` e `media_url` não podem estar vazias. Além disso, as datas precisam estar em conformidade, com `date_message` não sendo posterior a `date_system`. Também é importante identificar valores fora de contexto, como scores fora do intervalo esperado, e garantir que eles estejam dentro dos parâmetros lógicos. Essas verificações ajudam a aprimorar a qualidade e confiabilidade dos dados, possibilitando análises mais precisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65d9d314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de dados das colunas:\n",
      "date_message              datetime64[ns]\n",
      "id_member_anonymous               object\n",
      "id_group_anonymous                object\n",
      "media                             object\n",
      "media_type                        object\n",
      "media_url                         object\n",
      "has_media                           bool\n",
      "has_media_url                       bool\n",
      "trava_zap                           bool\n",
      "text_content_anonymous            object\n",
      "dataset_info_id                    int64\n",
      "date_system               datetime64[ns]\n",
      "score_sentiment                  float64\n",
      "score_misinformation             float64\n",
      "id_message                         int64\n",
      "message_type                      object\n",
      "messenger                         object\n",
      "media_name                        object\n",
      "media_md5                         object\n",
      "caracteres                         int64\n",
      "words                              int64\n",
      "viral                              int32\n",
      "sentiment                        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# APENAS PARA DEIXAR MAIS FÁCIL DE ACESSAR\n",
    "print(\"Tipos de dados das colunas:\")\n",
    "print(df_inicial.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1481e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esthe\\AppData\\Local\\Temp\\ipykernel_7524\\1876568694.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inicial['inconsistencia_verificada'] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistências de mídia encontradas: 0 linhas\n",
      "Empty DataFrame\n",
      "Columns: [id_message, has_media, media, media_type, media_url, media_name, media_md5]\n",
      "Index: []\n",
      "Inconsistências de data encontradas: 0 linhas\n",
      "Empty DataFrame\n",
      "Columns: [id_message, date_message, date_system]\n",
      "Index: []\n",
      "Inconsistências no 'score_misinformation' encontradas: 0 linhas\n",
      "Empty DataFrame\n",
      "Columns: [id_message, score_misinformation]\n",
      "Index: []\n",
      "Inconsistências no 'caracteres' encontradas: 0 linhas\n",
      "Empty DataFrame\n",
      "Columns: [id_message, text_content_anonymous, caracteres]\n",
      "Index: []\n",
      "\n",
      "Comparação real entre 'caracteres' informado e comprimento real:\n",
      "\n",
      "Total de inconsistências encontradas: 0\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o contador de inconsistências\n",
    "contador_inconsistencias = 0\n",
    "\n",
    "# Criar uma coluna auxiliar para marcar as linhas já verificadas como inconsistentes\n",
    "df_inicial['inconsistencia_verificada'] = False\n",
    "\n",
    "# Verificação de inconsistências de mídia: has_media = True e todas as colunas relacionadas a mídia são NaN\n",
    "colunas_midia = ['media', 'media_type', 'media_url', 'media_name', 'media_md5']\n",
    "inconsistencias_midia = df_inicial[\n",
    "    (df_inicial['has_media'] == True) &\n",
    "    (df_inicial[colunas_midia].isna().all(axis=1))\n",
    "]\n",
    "contador_inconsistencias += len(inconsistencias_midia)\n",
    "df_inicial.loc[inconsistencias_midia.index, 'inconsistencia_verificada'] = True\n",
    "print(f\"Inconsistências de mídia encontradas: {len(inconsistencias_midia)} linhas\")\n",
    "print(inconsistencias_midia[['id_message', 'has_media'] + colunas_midia])\n",
    "\n",
    "# Verificação de inconsistências de data (onde 'date_message' é maior que 'date_system')\n",
    "inconsistencias_data = df_inicial[(df_inicial['date_message'] > df_inicial['date_system']) & (~df_inicial['inconsistencia_verificada'])]\n",
    "contador_inconsistencias += len(inconsistencias_data)\n",
    "df_inicial.loc[inconsistencias_data.index, 'inconsistencia_verificada'] = True\n",
    "print(f\"Inconsistências de data encontradas: {contador_inconsistencias} linhas\")\n",
    "print(inconsistencias_data[['id_message', 'date_message', 'date_system']])\n",
    "\n",
    "# Verificação de inconsistências no 'score_misinformation' (fora da faixa [-1, 1])\n",
    "inconsistencias_misinformation = df_inicial[((df_inicial['score_misinformation'] < -1) | (df_inicial['score_misinformation'] > 1)) & (~df_inicial['inconsistencia_verificada'])]\n",
    "contador_inconsistencias += len(inconsistencias_misinformation)\n",
    "df_inicial.loc[inconsistencias_misinformation.index, 'inconsistencia_verificada'] = True\n",
    "print(f\"Inconsistências no 'score_misinformation' encontradas: {contador_inconsistencias} linhas\")\n",
    "print(inconsistencias_misinformation[['id_message', 'score_misinformation']])\n",
    "\n",
    "# Verificação de inconsistências no 'caracteres' (não corresponde ao tamanho de 'text_content_anonymous')\n",
    "inconsistencias_caracteres = df_inicial[\n",
    "    (df_inicial['caracteres'] != df_inicial['text_content_anonymous'].fillna('').str.len()) &\n",
    "    (~df_inicial['inconsistencia_verificada'])\n",
    "]\n",
    "\n",
    "contador_inconsistencias += len(inconsistencias_caracteres)\n",
    "df_inicial.loc[inconsistencias_caracteres.index, 'inconsistencia_verificada'] = True\n",
    "\n",
    "print(f\"Inconsistências no 'caracteres' encontradas: {len(inconsistencias_caracteres)} linhas\")\n",
    "print(inconsistencias_caracteres[['id_message', 'text_content_anonymous', 'caracteres']].head(10))\n",
    "print(\"\\nComparação real entre 'caracteres' informado e comprimento real:\")\n",
    "for idx, row in inconsistencias_caracteres.head(10).iterrows():\n",
    "    print(f\"ID {row['id_message']}: caracteres={row['caracteres']} | real={len(row['text_content_anonymous'] or '')}\")\n",
    "    \n",
    "\n",
    "# Exibir o total de inconsistências encontradas\n",
    "print(f\"\\nTotal de inconsistências encontradas: {contador_inconsistencias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21091c40",
   "metadata": {},
   "source": [
    "#### **Visualizando os dataframes finais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ee4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date_message               id_member_anonymous  \\\n",
      "0      2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
      "1      2022-10-05 06:25:08                               NaN   \n",
      "2      2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
      "3      2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
      "4      2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
      "...                    ...                               ...   \n",
      "557581 2022-11-11 12:06:15  333e9869f23dbd4682d1be382d9c1e59   \n",
      "557582 2022-11-11 12:09:08                               NaN   \n",
      "557583 2022-11-11 12:09:47                               NaN   \n",
      "557584 2022-11-11 12:09:46                               NaN   \n",
      "557585 2022-11-11 12:09:48                               NaN   \n",
      "\n",
      "                      id_group_anonymous  \\\n",
      "0       12283e08a2eb5789201e105b34489ee7   \n",
      "1       12283e08a2eb5789201e105b34489ee7   \n",
      "2       9f2d7394334eb224c061c9740b5748fc   \n",
      "3       c8f2de56550ed0bf85249608b7ead93d   \n",
      "4       e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "...                                  ...   \n",
      "557581  e56ec342fc599ebb4ed89655eb6f03aa   \n",
      "557582  5b10d7739171149be6d9961e3350c071   \n",
      "557583  1590a03f43b5ba4b6147a1c5e1dd357b   \n",
      "557584  5b10d7739171149be6d9961e3350c071   \n",
      "557585  b11f2df64ac19aad47a50accf32052d6   \n",
      "\n",
      "                                       media media_type  \\\n",
      "0                                        NaN        NaN   \n",
      "1                                        NaN        NaN   \n",
      "2                                        NaN        NaN   \n",
      "3       94dca4cda503100ebfda7ce2bcc060eb.jpg  image/jpg   \n",
      "4       5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg  image/jpg   \n",
      "...                                      ...        ...   \n",
      "557581  25e43b6a58b848c43ad5b5f9e979822a.jpg        url   \n",
      "557582  657949d03e4088f6b332e2686ccd3221.jpg        url   \n",
      "557583  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557584  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "557585  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
      "\n",
      "                                                media_url  has_media  \\\n",
      "0                                                     NaN      False   \n",
      "1                                                     NaN      False   \n",
      "2                                                     NaN      False   \n",
      "3                                                     NaN       True   \n",
      "4                                                     NaN       True   \n",
      "...                                                   ...        ...   \n",
      "557581  https://terrabrasilnoticias.com/2022/11/bndes-...       True   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk       True   \n",
      "557583                           https://t.me/vemprasruas       True   \n",
      "557584                           https://t.me/vemprasruas       True   \n",
      "557585                           https://t.me/vemprasruas       True   \n",
      "\n",
      "        has_media_url  trava_zap  \\\n",
      "0               False      False   \n",
      "1               False      False   \n",
      "2               False      False   \n",
      "3               False      False   \n",
      "4               False      False   \n",
      "...               ...        ...   \n",
      "557581           True      False   \n",
      "557582           True      False   \n",
      "557583           True      False   \n",
      "557584           True      False   \n",
      "557585           True      False   \n",
      "\n",
      "                                   text_content_anonymous  ...  id_message  \\\n",
      "0       Então é Fato Renato o áudio que eu ouvi no wha...  ...       16385   \n",
      "1       Saiu no YouTube do presidente a 8 horas atrás,...  ...       16386   \n",
      "2       É isso, nossa parte já foi quase toda feita. N...  ...       16366   \n",
      "3                GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA  ...       19281   \n",
      "4                                                     NaN  ...      507185   \n",
      "...                                                   ...  ...         ...   \n",
      "557581  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...  ...      575796   \n",
      "557582                       https://youtu.be/8g1Vz9_0xVk  ...     1286443   \n",
      "557583  Empresários, demitam os petistas primeiro.\\n\\n...  ...       13294   \n",
      "557584  Empresários, demitam os petistas primeiro.\\n\\n...  ...     1286444   \n",
      "557585  Empresários, demitam os petistas primeiro.\\n\\n...  ...      192127   \n",
      "\n",
      "       message_type  messenger  media_name                         media_md5  \\\n",
      "0             texto   telegram         NaN                               NaN   \n",
      "1             texto   telegram         NaN                               NaN   \n",
      "2             texto   telegram         NaN                               NaN   \n",
      "3            imagem   telegram         NaN  94dca4cda503100ebfda7ce2bcc060eb   \n",
      "4            imagem   telegram         NaN  5ad5c8bbe9da93a37fecf3e5aa5b0637   \n",
      "...             ...        ...         ...                               ...   \n",
      "557581          url   telegram         NaN  25e43b6a58b848c43ad5b5f9e979822a   \n",
      "557582          url   telegram         NaN  657949d03e4088f6b332e2686ccd3221   \n",
      "557583       imagem   telegram         NaN  a21848a61045380a6483866daed0ca0e   \n",
      "557584       imagem   telegram         NaN  a21848a61045380a6483866daed0ca0e   \n",
      "557585       imagem   telegram         NaN  a21848a61045380a6483866daed0ca0e   \n",
      "\n",
      "       caracteres words viral sentiment  inconsistencia_verificada  \n",
      "0             110    20     0       0.0                      False  \n",
      "1             141    23     0       1.0                      False  \n",
      "2             350    59     0      -1.0                      False  \n",
      "3              40     7     0       0.0                      False  \n",
      "4               0     0     0       NaN                      False  \n",
      "...           ...   ...   ...       ...                        ...  \n",
      "557581        152    12     1       1.0                      False  \n",
      "557582         28     1     1       0.0                      False  \n",
      "557583         68     6     1       0.0                      False  \n",
      "557584         68     6     1       0.0                      False  \n",
      "557585         68     6     1       0.0                      False  \n",
      "\n",
      "[557570 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# DF_FINAL COM AS LINHAS TRAVA-ZAPS REMOVIDAS\n",
    "print(df_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d42b2a",
   "metadata": {},
   "source": [
    "## Fontes\n",
    "- [StackOverflow - How to read CSV file from google drive public](https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public)\n",
    "- [Pandas: find rows/columns with NaN (missing values)](https://note.nkmk.me/en/python-pandas-nan-extract/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
